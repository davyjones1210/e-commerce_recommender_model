{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mmC6tGWV2yO",
        "outputId": "222eb01f-142b-441f-f5c4-01bf5bb20150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üõçÔ∏è Recommended Products:\n",
            "                           Product         Model  weighted_score\n",
            "   set 20 red spotty paper napkins       Apriori        0.250000\n",
            "          tea bag plate red spotty Collaborative        0.250000\n",
            " set 5 blue spotty lid glass bowls       Content        0.250000\n",
            "          regency cakestand 3 tier           RFM        0.250000\n",
            "white hanging heart t light holder           RFM        0.166667\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# FULL END-TO-END HYBRID RECOMMENDER\n",
        "# Uses DF_SAMPLE (1000 invoices)\n",
        "# =========================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# -------------------------\n",
        "# 0) Load and sample data\n",
        "# -------------------------\n",
        "df = pd.read_csv(\"combined_unique.csv\", encoding=\"latin-1\")\n",
        "\n",
        "# Keep required columns and drop rows missing required fields\n",
        "df = df[['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'Price', 'Customer ID', 'Country']].dropna(subset=['Invoice', 'Description', 'Price'])\n",
        "\n",
        "# Convert InvoiceDate to datetime if possible\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
        "\n",
        "# Random 1000 invoices sample (safe for Colab / local)\n",
        "sample_invoices = df['Invoice'].drop_duplicates().sample(1000, random_state=42)\n",
        "df_sample = df[df['Invoice'].isin(sample_invoices)].copy()\n",
        "\n",
        "# Ensure Customer ID exists (we keep null Customer ID rows for Apriori/content but not for CF/RFM)\n",
        "# We'll also create a numeric-safe CustomerID column for CF/RFM where possible\n",
        "df_sample['Customer ID'] = df_sample['Customer ID'].astype(str).replace('nan', np.nan)\n",
        "df_sample['CustomerID_numeric'] = pd.to_numeric(df_sample['Customer ID'], errors='coerce').astype('Int64')\n",
        "\n",
        "# Clean Description (lowercase, strip punctuation)\n",
        "df_sample['Description'] = (\n",
        "    df_sample['Description'].astype(str)\n",
        "    .str.lower()\n",
        "    .str.replace(r\"[^a-z0-9 ]\", \" \", regex=True)\n",
        "    .str.strip()\n",
        ")\n",
        "\n",
        "# For consistent downstream usage rename Customer column (we'll keep original 'Customer ID' too)\n",
        "df_sample = df_sample.rename(columns={\"Customer ID\": \"Customer ID\"})\n",
        "\n",
        "# -------------------------\n",
        "# 1) APRIORI (transaction ‚Üí items)\n",
        "#    (uses Invoice and Description; uses Price aggregation like your prior code)\n",
        "# -------------------------\n",
        "basket = (\n",
        "    df_sample.groupby(['Invoice', 'Description'])['Price']\n",
        "    .sum()\n",
        "    .unstack(fill_value=0)\n",
        ")\n",
        "# convert to 0/1\n",
        "basket = (basket > 0).astype(int)\n",
        "\n",
        "rules = pd.DataFrame()\n",
        "try:\n",
        "    frequent_itemsets = apriori(basket, min_support=0.01, use_colnames=True)\n",
        "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
        "except Exception as e:\n",
        "    print(\"Apriori failed or found no frequent itemsets:\", e)\n",
        "    rules = pd.DataFrame()\n",
        "\n",
        "def apriori_recommend(product, top_n=5):\n",
        "    product_norm = str(product).lower().strip()\n",
        "    if rules.empty:\n",
        "        return []\n",
        "    try:\n",
        "        related = rules[rules['antecedents'].apply(lambda s: product_norm in [str(i).lower().strip() for i in s])]\n",
        "        if related.empty:\n",
        "            return []\n",
        "        recs = (\n",
        "            related.sort_values('lift', ascending=False)\n",
        "                   .head(top_n)\n",
        "                   .apply(lambda x: list(x['consequents']), axis=1)\n",
        "                   .explode()\n",
        "                   .unique()\n",
        "                   .tolist()\n",
        "        )\n",
        "        return [str(r).lower().strip() for r in recs][:top_n]\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "# -------------------------\n",
        "# 2) COLLABORATIVE FILTERING (Item-item)\n",
        "#    (uses Customer ID and Description; drop missing Customer IDs)\n",
        "# -------------------------\n",
        "df_cf = df_sample.dropna(subset=['CustomerID_numeric', 'Description', 'Price']).copy()\n",
        "# create user-item matrix (Customer √ó Description) using total Price then binarize\n",
        "user_item = (\n",
        "    df_cf.groupby(['CustomerID_numeric', 'Description'])['Price']\n",
        "    .sum()\n",
        "    .unstack(fill_value=0)\n",
        ")\n",
        "user_item_bin = (user_item > 0).astype(int)\n",
        "\n",
        "item_similarity = cosine_similarity(user_item_bin.T)\n",
        "item_similarity_df = pd.DataFrame(item_similarity, index=user_item_bin.columns, columns=user_item_bin.columns)\n",
        "\n",
        "def collaborative_recommend(product, top_n=5):\n",
        "    product_norm = str(product).lower().strip()\n",
        "    if product_norm not in item_similarity_df.index:\n",
        "        # attempt fuzzy match: find descriptions containing product substring\n",
        "        candidates = [idx for idx in item_similarity_df.index if product_norm in idx]\n",
        "        if not candidates:\n",
        "            return []\n",
        "        prod = candidates[0]\n",
        "    else:\n",
        "        prod = product_norm\n",
        "    sim_scores = item_similarity_df[prod].sort_values(ascending=False)\n",
        "    recs = sim_scores.iloc[1: top_n + 1].index.tolist()  # exclude self\n",
        "    return [str(r).lower().strip() for r in recs]\n",
        "\n",
        "# -------------------------\n",
        "# 3) CONTENT-BASED (TF-IDF on Description)\n",
        "#    (deduplicate descriptions and average Price as before)\n",
        "# -------------------------\n",
        "df_content = (\n",
        "    df_sample.groupby('Description', as_index=False)['Price'].mean()\n",
        ")\n",
        "\n",
        "# Ensure cleaned descriptions\n",
        "df_content['Description'] = df_content['Description'].astype(str).str.lower().str.replace(r\"[^a-z0-9 ]\", \" \", regex=True).str.strip()\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df_content['Description'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "indices = pd.Series(df_content.index, index=df_content['Description']).drop_duplicates()\n",
        "\n",
        "def content_recommend(product, top_n=5):\n",
        "    product_norm = str(product).lower().strip()\n",
        "    # exact match or substring match\n",
        "    if product_norm not in indices:\n",
        "        matches = [p for p in indices.index if product_norm in p]\n",
        "        if not matches:\n",
        "            return []\n",
        "        product_norm = matches[0]\n",
        "    idx = indices[product_norm]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1: top_n + 1]\n",
        "    similar_indices = [i[0] for i in sim_scores]\n",
        "    return df_content.iloc[similar_indices]['Description'].astype(str).str.lower().tolist()\n",
        "\n",
        "# -------------------------\n",
        "# 4) RFM Model\n",
        "#    (uses InvoiceDate, Invoice, Price, Customer ID)\n",
        "# -------------------------\n",
        "df_rfm = df_sample.dropna(subset=['CustomerID_numeric', 'InvoiceDate']).copy()\n",
        "df_rfm = df_rfm[df_rfm['Quantity'] > 0]  # remove returns/negatives if any\n",
        "\n",
        "df_rfm['TotalAmount'] = df_rfm['Quantity'] * df_rfm['Price']\n",
        "snapshot_date = df_rfm['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
        "\n",
        "rfm = df_rfm.groupby('CustomerID_numeric').agg({\n",
        "    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,\n",
        "    'Invoice': 'nunique',\n",
        "    'TotalAmount': 'sum'\n",
        "}).reset_index().rename(columns={'InvoiceDate': 'Recency', 'Invoice': 'Frequency', 'TotalAmount': 'Monetary'})\n",
        "\n",
        "# Score R, F, M\n",
        "rfm['R_rank'] = pd.qcut(rfm['Recency'].rank(method='first'), 5, labels=[5,4,3,2,1]).astype(int)\n",
        "rfm['F_rank'] = pd.qcut(rfm['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5]).astype(int)\n",
        "rfm['M_rank'] = pd.qcut(rfm['Monetary'].rank(method='first'), 5, labels=[1,2,3,4,5]).astype(int)\n",
        "rfm['RFM_Score'] = rfm[['R_rank','F_rank','M_rank']].sum(axis=1)\n",
        "\n",
        "# Top customers (top 10%)\n",
        "top_n_customers = max(1, int(0.1 * len(rfm)))\n",
        "top_customers = rfm.sort_values('RFM_Score', ascending=False).head(top_n_customers)['CustomerID_numeric'].tolist()\n",
        "top_products = df_rfm[df_rfm['CustomerID_numeric'].isin(top_customers)]['Description'].value_counts().head(20).index.tolist()\n",
        "\n",
        "def rfm_recommend(product, top_n=5):\n",
        "    # simply return top_products as before\n",
        "    return [str(p).lower().strip() for p in top_products[:top_n]]\n",
        "\n",
        "# -------------------------\n",
        "# 5) FINAL ENSEMBLE (your provided function, unchanged)\n",
        "#    weights adjustable at top of this block\n",
        "# -------------------------\n",
        "# Model weights (edit if needed)\n",
        "W_APRIORI = 0.25\n",
        "W_COLLAB  = 0.25\n",
        "W_CONTENT = 0.25\n",
        "W_RFM     = 0.25\n",
        "\n",
        "def ensemble_recommend(product, top_n=5):\n",
        "    product_norm = str(product).lower().strip()\n",
        "    rows = []\n",
        "\n",
        "    # Apriori\n",
        "    if 'rules' in globals() and not rules.empty:\n",
        "        try:\n",
        "            related = rules[\n",
        "                rules['antecedents'].apply(\n",
        "                    lambda s: product_norm in [str(i).lower().strip() for i in s]\n",
        "                )\n",
        "            ]\n",
        "            for _, r in related.iterrows():\n",
        "                for c in r['consequents']:\n",
        "                    c = str(c).lower().strip()\n",
        "                    lift_score = float(r.get('lift', 1))\n",
        "                    rows.append((c, 'Apriori', lift_score))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Collaborative\n",
        "    try:\n",
        "        recs = collaborative_recommend(product_norm, top_n=10)\n",
        "        for rank, item in enumerate(recs):\n",
        "            item = str(item).lower().strip()\n",
        "            score = 1 / (rank + 1)\n",
        "            rows.append((item, 'Collaborative', score))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Content\n",
        "    try:\n",
        "        recs = content_recommend(product_norm, top_n=10)\n",
        "        for rank, item in enumerate(recs):\n",
        "            item = str(item).lower().strip()\n",
        "            score = 1 / (rank + 1)\n",
        "            rows.append((item, 'Content', score))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # RFM\n",
        "    try:\n",
        "        recs = rfm_recommend(product_norm, top_n=10)\n",
        "        for rank, item in enumerate(recs):\n",
        "            item = str(item).lower().strip()\n",
        "            score = 1 / (rank + 2)\n",
        "            rows.append((item, 'RFM', score))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    if not rows:\n",
        "        return pd.DataFrame(columns=['Product','Model','weighted_score'])\n",
        "\n",
        "    df_all = pd.DataFrame(rows, columns=['Product','Model','raw_score'])\n",
        "    # normalize within model\n",
        "    df_all['norm_score'] = df_all.groupby('Model')['raw_score'].transform(lambda s: s / s.max() if s.max() > 0 else 0)\n",
        "\n",
        "    weight_map = {'Apriori': W_APRIORI, 'Collaborative': W_COLLAB, 'Content': W_CONTENT, 'RFM': W_RFM}\n",
        "    df_all['weighted_score'] = df_all.apply(lambda x: x['norm_score'] * weight_map.get(x['Model'], 0), axis=1)\n",
        "\n",
        "    final_df = (df_all.sort_values('weighted_score', ascending=False)\n",
        "                      .drop_duplicates(subset=['Product'])\n",
        "                      .head(top_n)\n",
        "                      .reset_index(drop=True))\n",
        "\n",
        "    # restore original casing if df_content exists\n",
        "    if 'df_content' in globals():\n",
        "        mapping = {d.lower(): d for d in df_content['Description'].astype(str)}\n",
        "        final_df['Product'] = final_df['Product'].map(mapping).fillna(final_df['Product'])\n",
        "\n",
        "    return final_df[['Product','Model','weighted_score']]\n",
        "\n",
        "# -------------------------\n",
        "# 6) TEST the ensemble with single input (product page)\n",
        "# -------------------------\n",
        "test_product = \"set 5 red spotty lid glass bowls\"  # change as needed\n",
        "recommendations = ensemble_recommend(test_product, top_n=5)\n",
        "\n",
        "print(\"\\nüõçÔ∏è Recommended Products:\")\n",
        "print(recommendations.to_string(index=False))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dsi_participant",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
